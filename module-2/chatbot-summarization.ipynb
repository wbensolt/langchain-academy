{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "83fcadf3",
   "metadata": {},
   "source": [
    "[![Open in Colab](https://colab.research.google.com/assets/colab-badge.svg)](https://colab.research.google.com/github/langchain-ai/langchain-academy/blob/main/module-2/chatbot-summarization.ipynb) [![Open in LangChain Academy](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66e9eba12c7b7688aa3dbb5e_LCA-badge-green.svg)](https://academy.langchain.com/courses/take/intro-to-langgraph/lessons/58239436-lesson-5-chatbot-w-summarizing-messages-and-memory)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b651ead9-5504-45ee-938d-f91ac78dddd1",
   "metadata": {},
   "source": [
    "# Chatbot with message summarization\n",
    "\n",
    "## Review\n",
    "\n",
    "We've covered how to customize graph state schema and reducer. \n",
    " \n",
    "We've also shown a number of ways to trim or filter messages in graph state. \n",
    "\n",
    "## Goals\n",
    "\n",
    "Now, let's take it one step further! \n",
    "\n",
    "Rather than just trimming or filtering messages, we'll show how to use LLMs to produce a running summary of the conversation.\n",
    " \n",
    "This allows us to retain a compressed representation of the full conversation, rather than just removing it with trimming or filtering.\n",
    "\n",
    "We'll incorporate this summarization into a simple Chatbot.  \n",
    "\n",
    "And we'll equip that Chatbot with memory, supporting long-running conversations without incurring high token cost / latency. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "000a6daa-92ad-4e57-a060-d1c81176eb0d",
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install --quiet -U langchain_core langgraph langchain_openai"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "09201a62",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    if not os.environ.get(var):\n",
    "        os.environ[var] = getpass.getpass(f\"{var}: \")\n",
    "\n",
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "dfddfce9-3a9b-4b35-a76d-28265515aabd",
   "metadata": {},
   "source": [
    "We'll use [LangSmith](https://docs.smith.langchain.com/) for [tracing](https://docs.smith.langchain.com/concepts/tracing)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "464856d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "_set_env(\"LANGSMITH_API_KEY\")\n",
    "os.environ[\"LANGSMITH_TRACING\"] = \"true\"\n",
    "os.environ[\"LANGSMITH_PROJECT\"] = \"langchain-academy\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "537ade30-6a0e-4b6b-8bcd-ce90790b6392",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "model_ = ChatOpenAI(model=\"gpt-4o\",temperature=0)\n",
    "from dotenv import load_dotenv\n",
    "from langchain_groq import ChatGroq\n",
    "import os\n",
    "\n",
    "# Charge les variables d'environnement depuis le fichier .env\n",
    "load_dotenv()\n",
    "\n",
    "# Récupère ta clé d'API Groq\n",
    "api_key = os.getenv(\"GROQ_API_KEY\")\n",
    "\n",
    "# Initialisation du modèle ChatGroq avec ton modèle préféré\n",
    "model = ChatGroq(\n",
    "    model=\"meta-llama/llama-4-scout-17b-16e-instruct\",\n",
    "    temperature=0,\n",
    "    api_key=api_key\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "db3afac3-8b7a-45db-a3c1-7e4125c1bc8b",
   "metadata": {},
   "source": [
    "We'll use `MessagesState`, as before.\n",
    "\n",
    "In addition to the built-in `messages` key, we'll now include a custom key (`summary`)."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "948e60f0-5c76-4235-b40e-cf523205d40e",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import MessagesState\n",
    "class State(MessagesState):\n",
    "    summary: str"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6855ea31-5cc1-4277-a189-0b72459f67ec",
   "metadata": {},
   "source": [
    "We'll define a node to call our LLM that incorporates a summary, if it exists, into the prompt."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "c3f7d19b-afe0-4381-9b1a-0a832b162e7b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage, HumanMessage, RemoveMessage\n",
    "\n",
    "# Define the logic to call the model\n",
    "def call_model(state: State):\n",
    "    \n",
    "    # Get summary if it exists\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # If there is summary, then we add it\n",
    "    if summary:\n",
    "        \n",
    "        # Add summary to system message\n",
    "        system_message = f\"Summary of conversation earlier: {summary}\"\n",
    "\n",
    "        # Append summary to any newer messages\n",
    "        messages = [SystemMessage(content=system_message)] + state[\"messages\"]\n",
    "    \n",
    "    else:\n",
    "        messages = state[\"messages\"]\n",
    "    \n",
    "    response = model.invoke(messages)\n",
    "    return {\"messages\": response}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "6882042c-b42d-4d52-a6a7-6ec8efa72450",
   "metadata": {},
   "source": [
    "We'll define a node to produce a summary.\n",
    "\n",
    "Note, here we'll use `RemoveMessage` to filter our state after we've produced the summary."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "78c7aa59-3760-4e76-93f1-bc713e3ec39e",
   "metadata": {},
   "outputs": [],
   "source": [
    "def summarize_conversation(state: State):\n",
    "    \n",
    "    # First, we get any existing summary\n",
    "    summary = state.get(\"summary\", \"\")\n",
    "\n",
    "    # Create our summarization prompt \n",
    "    if summary:\n",
    "        \n",
    "        # A summary already exists\n",
    "        summary_message = (\n",
    "            f\"This is summary of the conversation to date: {summary}\\n\\n\"\n",
    "            \"Extend the summary by taking into account the new messages above:\"\n",
    "        )\n",
    "        \n",
    "    else:\n",
    "        summary_message = \"Create a summary of the conversation above:\"\n",
    "\n",
    "    # Add prompt to our history\n",
    "    messages = state[\"messages\"] + [HumanMessage(content=summary_message)]\n",
    "    print(f\"Les messages passés : {messages}\")\n",
    "    response = model.invoke(messages)\n",
    "    print(f\"La reponse est : {response.content}\")\n",
    "    # Delete all but the 2 most recent messages\n",
    "    delete_messages = [RemoveMessage(id=m.id) for m in state[\"messages\"][:-2]]\n",
    "    return {\"summary\": response.content, \"messages\": delete_messages}"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f982993e-f4be-4ff7-9a38-886f75398b3d",
   "metadata": {},
   "source": [
    "We'll add a conditional edge to determine whether to produce a summary based on the conversation length."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "b507665d-7f5d-442a-b498-218c94c5dd8b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph.graph import END\n",
    "# Determine whether to end or summarize the conversation\n",
    "def should_continue(state: State):\n",
    "    \n",
    "    \"\"\"Return the next node to execute.\"\"\"\n",
    "    \n",
    "    messages = state[\"messages\"]\n",
    "    \n",
    "    # If there are more than six messages, then we summarize the conversation\n",
    "    if len(messages) > 6:\n",
    "        return \"summarize_conversation\"\n",
    "    \n",
    "    # Otherwise we can just end\n",
    "    return END"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5a838f4c-7067-4f7f-a4c4-6654e11214cd",
   "metadata": {},
   "source": [
    "## Adding memory\n",
    "\n",
    "Recall that [state is transient](https://github.com/langchain-ai/langgraph/discussions/352#discussioncomment-9291220) to a single graph execution.\n",
    "\n",
    "This limits our ability to have multi-turn conversations with interruptions. \n",
    "\n",
    "As introduced at the end of Module 1, we can use [persistence](https://langchain-ai.github.io/langgraph/how-tos/persistence/) to address this! \n",
    " \n",
    "LangGraph can use a checkpointer to automatically save the graph state after each step.\n",
    "\n",
    "This built-in persistence layer gives us memory, allowing LangGraph to pick up from the last state update. \n",
    "\n",
    "As we previously showed, one of the easiest to work with is `MemorySaver`, an in-memory key-value store for Graph state.\n",
    "\n",
    "All we need to do is compile the graph with a checkpointer, and our graph has memory!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "1d57516d-f9f1-4d3c-a84a-7277b5ce6df6",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, START\n",
    "\n",
    "# Define a new graph\n",
    "workflow = StateGraph(State)\n",
    "workflow.add_node(\"conversation\", call_model)\n",
    "workflow.add_node(summarize_conversation)\n",
    "\n",
    "# Set the entrypoint as conversation\n",
    "workflow.add_edge(START, \"conversation\")\n",
    "workflow.add_conditional_edges(\"conversation\", should_continue)\n",
    "workflow.add_edge(\"summarize_conversation\", END)\n",
    "\n",
    "# Compile\n",
    "memory = MemorySaver()\n",
    "graph = workflow.compile(checkpointer=memory)\n",
    "display(Image(graph.get_graph().draw_mermaid_png()))"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d0bd5d23-ac3b-4496-a049-9a9f97d2feb9",
   "metadata": {},
   "source": [
    "## Threads\n",
    "\n",
    "The checkpointer saves the state at each step as a checkpoint.\n",
    "\n",
    "These saved checkpoints can be grouped into a `thread` of conversation.\n",
    "\n",
    "Think about Slack as an analog: different channels carry different conversations.\n",
    "\n",
    "Threads are like Slack channels, capturing grouped collections of state (e.g., conversation).\n",
    "\n",
    "Below, we use `configurable` to set a thread ID.\n",
    "\n",
    "![state.jpg](https://cdn.prod.website-files.com/65b8cd72835ceeacd4449a53/66dbadf3b379c2ee621adfd1_chatbot-summarization1.png)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2566c93b-13e6-4a53-bc0f-b00fff691d30",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Lance\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Lance! Nice to meet you! Is there something I can help you with or would you like to chat?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Lance\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Lance! Nice to meet you! Is there something I can help you with or would you like to chat?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "what's my name?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your name is Lance! You told me that when we started chatting. How's your day going so far, Lance?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Lance\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Lance! Nice to meet you! Is there something I can help you with or would you like to chat?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "what's my name?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your name is Lance! You told me that when we started chatting. How's your day going so far, Lance?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "i like the 49ers!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Go Niners! The San Francisco 49ers have a rich history and a loyal fan base. Who's your favorite player, past or present? Are you a fan of the current team or do you have a favorite player from the past, like Joe Montana or Jerry Rice?\n"
     ]
    },
    {
     "ename": "",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31mThe Kernel crashed while executing code in the current cell or a previous cell. \n",
      "\u001b[1;31mPlease review the code in the cell(s) to identify a possible cause of the failure. \n",
      "\u001b[1;31mClick <a href='https://aka.ms/vscodeJupyterKernelCrash'>here</a> for more info. \n",
      "\u001b[1;31mView Jupyter <a href='command:jupyter.viewOutput'>log</a> for further details."
     ]
    }
   ],
   "source": [
    "# Create a thread\n",
    "config = {\"configurable\": {\"thread_id\": \"1\"}}\n",
    "\n",
    "# Start conversation\n",
    "input_message = HumanMessage(content=\"hi! I'm Lance\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages']:\n",
    "    m.pretty_print()\n",
    "\n",
    "input_message = HumanMessage(content=\"what's my name?\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages']:\n",
    "    m.pretty_print()\n",
    "\n",
    "input_message = HumanMessage(content=\"i like the 49ers!\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "df078b58",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "hi! I'm Lance\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Lance! Nice to meet you! Is there something I can help you with or would you like to chat?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "what's my name?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Your name is Lance! You told me that when we started chatting. How's your day going so far, Lance?\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "i like the 49ers!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Go Niners! The San Francisco 49ers have a rich history and a loyal fan base. Who's your favorite player, past or present? Are you a fan of the current team or do you have a favorite player from the past, like Joe Montana or Jerry Rice?\n"
     ]
    }
   ],
   "source": [
    "for m in output['messages']:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "531e5b63-5e8b-486e-baa0-a45521e2fbc2",
   "metadata": {},
   "source": [
    "Now, we don't yet have a summary of the state because we still have < = 6 messages.\n",
    "\n",
    "This was set in `should_continue`. \n",
    "\n",
    "```\n",
    "    # If there are more than six messages, then we summarize the conversation\n",
    "    if len(messages) > 6:\n",
    "        return \"summarize_conversation\"\n",
    "```\n",
    "\n",
    "We can pick up the conversation because we have the thread."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "91b82aaa-17f9-49e2-9528-f4b22e23ebcb",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "''"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state(config).values.get(\"summary\",\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "068a93e9-f716-4980-8edf-94115017d865",
   "metadata": {},
   "source": [
    "The `config` with thread ID allows us to proceed from the previously logged state!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "24b34f0f-62ef-4008-8e96-480cbe92ea3e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Les messages passés : [HumanMessage(content=\"hi! I'm Lance\", additional_kwargs={}, response_metadata={}, id='9abe6ef2-ba92-48dd-9c0b-132736aebd00'), AIMessage(content='Hi Lance! Nice to meet you! Is there something I can help you with or would you like to chat?', additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 24, 'prompt_tokens': 14, 'total_tokens': 38, 'completion_time': 0.054934675, 'prompt_time': 0.000315895, 'queue_time': 0.09167848, 'total_time': 0.05525057}, 'model_name': 'meta-llama/llama-4-scout-17b-16e-instruct', 'system_fingerprint': 'fp_37da608fc1', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--68d694c0-c16e-4c7c-aeb5-19081033439e-0', usage_metadata={'input_tokens': 14, 'output_tokens': 24, 'total_tokens': 38}), HumanMessage(content=\"what's my name?\", additional_kwargs={}, response_metadata={}, id='b59ee61a-18f4-46fd-956a-66de3c2dfc42'), AIMessage(content=\"Your name is Lance! You told me that when we started chatting. How's your day going so far, Lance?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 25, 'prompt_tokens': 52, 'total_tokens': 77, 'completion_time': 0.058658594, 'prompt_time': 0.00122601, 'queue_time': 0.089046172, 'total_time': 0.059884604}, 'model_name': 'meta-llama/llama-4-scout-17b-16e-instruct', 'system_fingerprint': 'fp_79da0e0073', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--098e8b97-152f-430c-ab9d-1ed6ef786d79-0', usage_metadata={'input_tokens': 52, 'output_tokens': 25, 'total_tokens': 77}), HumanMessage(content='i like the 49ers!', additional_kwargs={}, response_metadata={}, id='4f80ef24-0541-48ad-aa53-dd050db087ce'), AIMessage(content=\"Go Niners! The San Francisco 49ers have a rich history and a loyal fan base. Who's your favorite player, past or present? Are you a fan of the current team or do you have a favorite player from the past, like Joe Montana or Jerry Rice?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 57, 'prompt_tokens': 92, 'total_tokens': 149, 'completion_time': 0.152954872, 'prompt_time': 0.002252096, 'queue_time': 0.089133212, 'total_time': 0.155206968}, 'model_name': 'meta-llama/llama-4-scout-17b-16e-instruct', 'system_fingerprint': 'fp_37da608fc1', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--88d2ccad-fea0-41bc-a843-92309ac6872d-0', usage_metadata={'input_tokens': 92, 'output_tokens': 57, 'total_tokens': 149}), HumanMessage(content=\"i like Nick Bosa, isn't he the highest paid defensive player?\", additional_kwargs={}, response_metadata={}, id='5106e90e-29af-4473-b2e5-4234fc446432'), AIMessage(content=\"Nick Bosa is an incredible player! He's definitely one of the top defensive players in the league. According to recent reports, Nick Bosa did sign a massive contract extension with the 49ers, making him one of the highest-paid defensive players in the NFL. He signed a 5-year, $170 million deal, with $110 million guaranteed.\\n\\nBosa has been dominating on the field, and it's great to see him getting recognized with a well-deserved big contract. What do you think about his impact on the 49ers' defense?\", additional_kwargs={}, response_metadata={'token_usage': {'completion_tokens': 113, 'prompt_tokens': 171, 'total_tokens': 284, 'completion_time': 0.260853518, 'prompt_time': 0.004605302, 'queue_time': 0.09227382, 'total_time': 0.26545882}, 'model_name': 'meta-llama/llama-4-scout-17b-16e-instruct', 'system_fingerprint': 'fp_37da608fc1', 'service_tier': 'on_demand', 'finish_reason': 'stop', 'logprobs': None}, id='run--4bfb77fd-4899-49e0-a9ff-95eac083c3e3-0', usage_metadata={'input_tokens': 171, 'output_tokens': 113, 'total_tokens': 284}), HumanMessage(content='Create a summary of the conversation above:', additional_kwargs={}, response_metadata={})]\n",
      "La reponse est : Here's a summary of our conversation:\n",
      "\n",
      "* You introduced yourself as Lance.\n",
      "* You mentioned that you like the San Francisco 49ers.\n",
      "* You expressed your admiration for Nick Bosa, a defensive player for the 49ers.\n",
      "* You asked if Nick Bosa is the highest-paid defensive player, and I confirmed that he recently signed a large contract extension, making him one of the highest-paid defensive players in the NFL.\n",
      "\n",
      "Let me know if you'd like to chat about anything else, Lance!\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Nick Bosa is an incredible player! He's definitely one of the top defensive players in the league. According to recent reports, Nick Bosa did sign a massive contract extension with the 49ers, making him one of the highest-paid defensive players in the NFL. He signed a 5-year, $170 million deal, with $110 million guaranteed.\n",
      "\n",
      "Bosa has been dominating on the field, and it's great to see him getting recognized with a well-deserved big contract. What do you think about his impact on the 49ers' defense?\n"
     ]
    }
   ],
   "source": [
    "input_message = HumanMessage(content=\"i like Nick Bosa, isn't he the highest paid defensive player?\")\n",
    "output = graph.invoke({\"messages\": [input_message]}, config) \n",
    "for m in output['messages'][-1:]:\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "22f1b35f-e4bb-47f6-87b1-d84d8aed9aa9",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "\"Lance introduced himself and mentioned that he is a fan of the San Francisco 49ers. He specifically likes Nick Bosa and inquired if Bosa is the highest-paid defensive player. I confirmed that Nick Bosa signed a record-breaking contract extension in September 2023, making him the highest-paid defensive player at that time, and acknowledged Bosa's talent and Lance's enthusiasm for the player.\""
      ]
     },
     "execution_count": 14,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "graph.get_state(config).values.get(\"summary\",\"\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ad7cc0ab-905a-4037-b7cb-69db5b89591e",
   "metadata": {},
   "source": [
    "## LangSmith\n",
    "\n",
    "Let's review the trace!"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "academyenv",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
