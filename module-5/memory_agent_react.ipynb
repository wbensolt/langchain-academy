{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Tool calling \n",
    "\n",
    "#### With `bind_tools`\n",
    "Decide whether to save memories based on the conversation with the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "\n",
    "# Define the memory schema\n",
    "class Memory(BaseModel):\n",
    "    \"\"\" Format of memories extracted from the conversation. \"\"\"\n",
    "    content: str = Field(description=\"The main content of the memory. For example: User expressed interest in learning about French.\")\n",
    "    context: str = Field(description=\"Additional context for the memory. For example: This was mentioned while discussing career options in Europe.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Initialize the model\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Bind Memory schema as a tool to the model\n",
    "model_with_tools = model.bind_tools([Memory])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Invoke the model with general conversation\n",
    "output = model_with_tools.invoke([HumanMessage(\"Hi!\")])\n",
    "output.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  SaveMemory (call_sZG4bcHXxfTg2cXOC3Pd5DjV)\n",
      " Call ID: call_sZG4bcHXxfTg2cXOC3Pd5DjV\n",
      "  Args:\n",
      "    store_memories: True\n"
     ]
    }
   ],
   "source": [
    "# Invoke the model with personal information, which should trigger the tool call\n",
    "output = model_with_tools.invoke([HumanMessage(\"My name is Lance, I like to bike.\")])\n",
    "output.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 101,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'name': 'SaveMemory',\n",
       " 'args': {'store_memories': True},\n",
       " 'id': 'call_sZG4bcHXxfTg2cXOC3Pd5DjV',\n",
       " 'type': 'tool_call'}"
      ]
     },
     "execution_count": 101,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "output.tool_calls[0] "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### With `Trustcall`\n",
    "\n",
    "We can use [Trustcall](https://github.com/hinthornw/trustcall) as an extension of `bind_tools`.\n",
    "\n",
    "Before, we used `tool_choice=`, to enforces use of the the schema tool that we passed. \n",
    "\n",
    "In the context of an agent, we want to allow the model to choose whether to use the tool or not!\n",
    "\n",
    "So, we omit this. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from trustcall import create_extractor\n",
    "\n",
    "# Create the extractor\n",
    "trustcall_extractor = create_extractor(\n",
    "    model,\n",
    "    tools=[Memory],\n",
    "    enable_inserts=True,\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langchain_core.messages import SystemMessage\n",
    "\n",
    "# Create instruction for the extractor\n",
    "instruction = \"\"\"You are are a helpful assistant. You have access to a memory tool. First call the memory tool if any personal information is mentioned. Then, once the memories are saved, respond to the user's message naturally.\"\"\"\n",
    "\n",
    "# Invoke the extractor\n",
    "result = trustcall_extractor.invoke({\"messages\": [SystemMessage(content=instruction), HumanMessage(\"Hi!\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hello! How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# Message from the model \n",
    "for m in result[\"messages\"]: \n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {},
   "outputs": [],
   "source": [
    "# The resulting schemas,if applicable (none in this case)\n",
    "for m in result[\"responses\"]: \n",
    "    print(m)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now, let's invoke the extractor with a message that contains personal information. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the extractor\n",
    "result = trustcall_extractor.invoke({\"messages\": [SystemMessage(content=instruction), HumanMessage(\"My name is Lance, I like to bike.\")]})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Memory (call_oT9UcXzM9FYrBPZKIdmRUN84)\n",
      " Call ID: call_oT9UcXzM9FYrBPZKIdmRUN84\n",
      "  Args:\n",
      "    content: User's name is Lance.\n",
      "    context: User introduced themselves.\n",
      "  Memory (call_RQvw2im33gvxHIqFcNVUlFNh)\n",
      " Call ID: call_RQvw2im33gvxHIqFcNVUlFNh\n",
      "  Args:\n",
      "    content: User likes to bike.\n",
      "    context: User shared their hobbies.\n"
     ]
    }
   ],
   "source": [
    "# Messages from the model indicate two tool calls were made\n",
    "for m in result[\"messages\"]: \n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 96,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Memory',\n",
       "  'args': {'content': 'User likes to bike in Marin Headlands.',\n",
       "   'context': 'User shared their hobbies.'},\n",
       "  'id': 'call_JegriWiqzOMwCuuVpZWw4shQ',\n",
       "  'type': 'tool_call'},\n",
       " {'name': 'Memory',\n",
       "  'args': {'content': 'User likes to go to bakeries.',\n",
       "   'context': 'User shared their hobbies.'},\n",
       "  'id': 'call_M4r7EzCAEAPdJhEexjpgSAth',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 96,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "result[\"messages\"][0].tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 91,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[{'name': 'Memory',\n",
       "  'args': {'content': 'User likes to bike in Marin Headlands.',\n",
       "   'context': 'User shared their hobbies.'},\n",
       "  'id': 'call_JegriWiqzOMwCuuVpZWw4shQ',\n",
       "  'type': 'tool_call'},\n",
       " {'name': 'Memory',\n",
       "  'args': {'content': 'User likes to go to bakeries.',\n",
       "   'context': 'User shared their hobbies.'},\n",
       "  'id': 'call_M4r7EzCAEAPdJhEexjpgSAth',\n",
       "  'type': 'tool_call'}]"
      ]
     },
     "execution_count": 91,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "m.tool_calls"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': \"User's name is Lance.\", 'context': 'User introduced themselves.'}\n",
      "{'content': 'User likes to bike.', 'context': 'User shared their hobbies.'}\n"
     ]
    }
   ],
   "source": [
    "# We can see the resulting memories that are resolved from the tool calls\n",
    "for m in result[\"responses\"]: \n",
    "    print(m.model_dump(mode=\"json\"))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[('0',\n",
       "  'Memory',\n",
       "  {'content': \"User's name is Lance.\",\n",
       "   'context': 'User introduced themselves.'}),\n",
       " ('1',\n",
       "  'Memory',\n",
       "  {'content': 'User likes to bike.', 'context': 'User shared their hobbies.'})]"
      ]
     },
     "execution_count": 60,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# We'll save these memories, giving them an ID, key, and value\n",
    "tool_name = \"Memory\"\n",
    "existing_memories = [(str(i), tool_name, memory.model_dump()) for i, memory in enumerate(result[\"responses\"])] if result[\"responses\"] else None\n",
    "existing_memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Invoke the extractor with a follow-up message and pass in our existing memories\n",
    "result = trustcall_extractor.invoke({\"messages\": [HumanMessage(content=\"I like to bike in Marin Headlands. I also like to go to bakeries.\")], \n",
    "                                     \"existing\": existing_memories})"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "dict"
      ]
     },
     "execution_count": 79,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "type(result)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 80,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Memory (call_JegriWiqzOMwCuuVpZWw4shQ)\n",
      " Call ID: call_JegriWiqzOMwCuuVpZWw4shQ\n",
      "  Args:\n",
      "    content: User likes to bike in Marin Headlands.\n",
      "    context: User shared their hobbies.\n",
      "  Memory (call_M4r7EzCAEAPdJhEexjpgSAth)\n",
      " Call ID: call_M4r7EzCAEAPdJhEexjpgSAth\n",
      "  Args:\n",
      "    content: User likes to go to bakeries.\n",
      "    context: User shared their hobbies.\n"
     ]
    }
   ],
   "source": [
    "# Messages from the model indicate two tool calls were made\n",
    "for m in result[\"messages\"]: \n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 71,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'content': 'User likes to bike in Marin Headlands.', 'context': 'User shared their hobbies.'}\n",
      "{'content': 'User likes to go to bakeries.', 'context': 'User shared their hobbies.'}\n"
     ]
    }
   ],
   "source": [
    "# We can see the resulting memories that are resolved from the tool calls\n",
    "for m in result[\"responses\"]: \n",
    "    print(m.model_dump(mode=\"json\"))\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We make an update to `existing_memories`."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'id': 'call_eao9zMXBA9Cm5ERlZWTjdW8p', 'json_doc_id': '1'}\n",
      "{'id': 'call_hU2zUDM3AJh2FHamY220d9m6'}\n"
     ]
    }
   ],
   "source": [
    "# We can see the resulting memories that are resolved from the tool calls\n",
    "for m in result[\"response_metadata\"]: \n",
    "    print(m)\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### React agent \n",
    "\n",
    "Decide whether to save memories based on the conversation with the user."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 102,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "from IPython.display import Image, display\n",
    "\n",
    "import uuid\n",
    "\n",
    "from datetime import datetime\n",
    "from dataclasses import dataclass\n",
    "\n",
    "from typing_extensions import Annotated\n",
    "\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_core.messages import merge_message_runs\n",
    "from langchain_core.messages import HumanMessage, SystemMessage, ToolMessage, AnyMessage\n",
    "\n",
    "from langgraph.graph import START, END, MessagesState, StateGraph\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "from langgraph.store.base import BaseStore\n",
    "\n",
    "# Schema for storing memories\n",
    "class Memory(BaseModel):\n",
    "    content: str = Field(description=\"The main content of the memory. For example: User expressed interest in learning about French.\")\n",
    "    context: str = Field(description=\"Additional context for the memory. For example: This was mentioned while discussing career options in Europe.\")\n",
    "\n",
    "# Create the Trustcall extractor\n",
    "trustcall_extractor = create_extractor(\n",
    "    model,\n",
    "    tools=[Memory],\n",
    "    enable_inserts=True,\n",
    ")\n",
    "\n",
    "class State(MessagesState):\n",
    "    extracted_memories: dict = {}\n",
    "\n",
    "# Node definitions\n",
    "def call_model(state: State, config: RunnableConfig, *, store: BaseStore) -> dict:\n",
    "\n",
    "    \"\"\"Load memories from the store and use them to personalize the chatbot's response.\"\"\"\n",
    "    \n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Define the namespace for the memories\n",
    "    namespace = (\"memories\", user_id)\n",
    "\n",
    "    # Retrieve the most recent memories for context\n",
    "    existing_items = store.search(namespace)\n",
    "\n",
    "    # Format the existing memories for the Trustcall extractor\n",
    "    tool_name = \"Memory\"\n",
    "    existing_memories = ([(existing_item.key, tool_name, existing_item.value)\n",
    "                          for existing_item in existing_items]\n",
    "                          if existing_items\n",
    "                          else None\n",
    "                        )\n",
    "\n",
    "    system_msg = f\"\"\"You are are a helpful assistant. You have access to a memory tool. \n",
    "    First call the memory tool if any personal information is mentioned in the below conversation. \n",
    "    Then, once the memories are saved, respond to the user's message naturally.  \n",
    "    Use any existing memoried to personalize your responses.\n",
    "    Here are your memories (it may be empty): {existing_memories}\"\"\"\n",
    "\n",
    "    # Invoke the extractor with existing memories and the chat history\n",
    "    result = trustcall_extractor.invoke({\"messages\": [SystemMessage(content=system_msg)] + state[\"messages\"], \n",
    "                                         \"existing\": existing_memories})\n",
    "\n",
    "    # Trustcall output \n",
    "    trustcall_messages = result[\"messages\"] \n",
    "    trustcall_memories = result[\"responses\"]\n",
    "    trustcall_memories_metadata = result[\"response_metadata\"]\n",
    "\n",
    "    return {\"messages\": trustcall_messages, \"extracted_memories\": result}\n",
    "\n",
    "def store_memory(state: State, config: RunnableConfig, *, store: BaseStore):\n",
    "\n",
    "    \"\"\"Reflect on the chat history and update the memory collection.\"\"\"\n",
    "    \n",
    "    # Tool call to decide to save memories\n",
    "    trustcall_results = state['extracted_memories']\n",
    "\n",
    "    # List of tool calls\n",
    "    trustcall_tool_calls = trustcall_results[\"messages\"][0].tool_calls\n",
    "    # List of memories that were extracted from the tool calls\n",
    "    trustcall_memories = trustcall_results[\"responses\"]\n",
    "    # Metadata about the memories that were extracted from the tool calls\n",
    "    trustcall_memories_metadata = trustcall_results[\"response_metadata\"]\n",
    "\n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Define the namespace for the memories\n",
    "    namespace = (\"memories\", user_id)\n",
    "\n",
    "    # Save the memories from Trustcall to the store\n",
    "    for r, rmeta in zip(trustcall_memories, trustcall_memories_metadata):\n",
    "        store.put(namespace,\n",
    "                  rmeta.get(\"json_doc_id\", str(uuid.uuid4())),\n",
    "                  r.model_dump(mode=\"json\"),\n",
    "            )\n",
    "\n",
    "    # Tool message to confirm Trustcall outputs were saved to store\n",
    "    trustcall_tool_confirmation = [\n",
    "        ToolMessage(content=mem, tool_call_id=tc[\"id\"])\n",
    "        for tc, mem in zip(trustcall_tool_calls, trustcall_memories)\n",
    "    ]\n",
    "\n",
    "    return {\"messages\": trustcall_tool_confirmation}\n",
    "\n",
    "# Conditional edge\n",
    "def route_message(state: State):\n",
    "\n",
    "    \"\"\"Determine the next step based on the presence of tool calls.\"\"\"\n",
    "\n",
    "    # Get the last message\n",
    "    msg = state['messages'][-1]\n",
    "\n",
    "    # If there is a tool call, the model has decided to save memories\n",
    "    if msg.tool_calls:\n",
    "        # Direct to the store_memory node to save the memories\n",
    "        return \"store_memory\"\n",
    "    # Otherwise, finish; user can send the next message\n",
    "    return END\n",
    "\n",
    "# Create the graph + all nodes\n",
    "builder = StateGraph(State)\n",
    "\n",
    "# Define the flow of the memory extraction process\n",
    "builder.add_node(call_model)\n",
    "builder.add_node(store_memory)\n",
    "builder.add_edge(\"__start__\", \"call_model\")\n",
    "builder.add_conditional_edges(\"call_model\", route_message, [\"store_memory\", END])\n",
    "builder.add_edge(\"store_memory\", \"call_model\")\n",
    "\n",
    "# Store for long-term (across-thread) memory\n",
    "across_thread_memory = InMemoryStore()\n",
    "\n",
    "# Checkpointer for short-term (within-thread) memory\n",
    "within_thread_memory = MemorySaver()\n",
    "\n",
    "# We compile the graph with the checkpointer and store\n",
    "graph = builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 103,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, my name is Lance\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Memory (call_rWosGE2av1In75gmhjj9Zsb0)\n",
      " Call ID: call_rWosGE2av1In75gmhjj9Zsb0\n",
      "  Args:\n",
      "    content: User's name is Lance.\n",
      "    context: User introduced themselves.\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "content=\"User's name is Lance.\" context='User introduced themselves.'\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Memory (call_FJnl1K2S3tN3gaPTS5KtpPCV)\n",
      " Call ID: call_FJnl1K2S3tN3gaPTS5KtpPCV\n",
      "  Args:\n",
      "    content: User's name is Lance.\n",
      "    context: User introduced themselves.\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "content=\"User's name is Lance.\" context='User introduced themselves.'\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Memory (call_f9W0PfdGoIi5WpxTx4K0uXlF)\n",
      " Call ID: call_f9W0PfdGoIi5WpxTx4K0uXlF\n",
      "  Args:\n",
      "    content: User's name is Lance.\n",
      "    context: User introduced themselves.\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "content=\"User's name is Lance.\" context='User introduced themselves.'\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Memory (call_L5ppw7BYIBx4aEKc8RgD9iLR)\n",
      " Call ID: call_L5ppw7BYIBx4aEKc8RgD9iLR\n",
      "  Args:\n",
      "    content: User's name is Lance.\n",
      "    context: User introduced themselves.\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "content=\"User's name is Lance.\" context='User introduced themselves.'\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Memory (call_wFypTkHvMLP8SM6D41KdBtG8)\n",
      " Call ID: call_wFypTkHvMLP8SM6D41KdBtG8\n",
      "  Args:\n",
      "    content: User's name is Lance.\n",
      "    context: User introduced themselves.\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "content=\"User's name is Lance.\" context='User introduced themselves.'\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Memory (call_IVoaCR3qEq5lV6Y3Yz3OQxlv)\n",
      " Call ID: call_IVoaCR3qEq5lV6Y3Yz3OQxlv\n",
      "  Args:\n",
      "    content: User's name is Lance.\n",
      "    context: User introduced themselves.\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "content=\"User's name is Lance.\" context='User introduced themselves.'\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Memory (call_VAByR9w4CF1vrp4fsoFxN3Jc)\n",
      " Call ID: call_VAByR9w4CF1vrp4fsoFxN3Jc\n",
      "  Args:\n",
      "    content: User's name is Lance.\n",
      "    context: User introduced themselves.\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "content=\"User's name is Lance.\" context='User introduced themselves.'\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Memory (call_pOI0OexFYucaSovE6F0UTVJM)\n",
      " Call ID: call_pOI0OexFYucaSovE6F0UTVJM\n",
      "  Args:\n",
      "    content: User's name is Lance.\n",
      "    context: User introduced themselves.\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "content=\"User's name is Lance.\" context='User introduced themselves.'\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Memory (call_fEsjxuHywimVVfN2k5OB1mOQ)\n",
      " Call ID: call_fEsjxuHywimVVfN2k5OB1mOQ\n",
      "  Args:\n",
      "    content: User's name is Lance.\n",
      "    context: User introduced themselves.\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "content=\"User's name is Lance.\" context='User introduced themselves.'\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Memory (call_7Mfotha7cnEd3HJTruIsYMzm)\n",
      " Call ID: call_7Mfotha7cnEd3HJTruIsYMzm\n",
      "  Args:\n",
      "    content: User's name is Lance.\n",
      "    context: User introduced themselves.\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "content=\"User's name is Lance.\" context='User introduced themselves.'\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Memory (call_VtktjCGoU1RT3KNLbIDvzy88)\n",
      " Call ID: call_VtktjCGoU1RT3KNLbIDvzy88\n",
      "  Args:\n",
      "    content: User's name is Lance.\n",
      "    context: User introduced themselves.\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "content=\"User's name is Lance.\" context='User introduced themselves.'\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Memory (call_whSQdbnHiFsziOuKrJnfnDwT)\n",
      " Call ID: call_whSQdbnHiFsziOuKrJnfnDwT\n",
      "  Args:\n",
      "    content: User's name is Lance.\n",
      "    context: User introduced themselves.\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "content=\"User's name is Lance.\" context='User introduced themselves.'\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  Memory (call_luuudVxeumsBRUwN2Ejgff48)\n",
      " Call ID: call_luuudVxeumsBRUwN2Ejgff48\n",
      "  Args:\n",
      "    content: User's name is Lance.\n",
      "    context: User introduced themselves.\n"
     ]
    },
    {
     "ename": "GraphRecursionError",
     "evalue": "Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mGraphRecursionError\u001b[0m                       Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[103], line 9\u001b[0m\n\u001b[1;32m      6\u001b[0m input_messages \u001b[38;5;241m=\u001b[39m [HumanMessage(content\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mHi, my name is Lance\u001b[39m\u001b[38;5;124m\"\u001b[39m)]\n\u001b[1;32m      8\u001b[0m \u001b[38;5;66;03m# Run the graph\u001b[39;00m\n\u001b[0;32m----> 9\u001b[0m \u001b[38;5;28;43;01mfor\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;129;43;01min\u001b[39;49;00m\u001b[43m \u001b[49m\u001b[43mgraph\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mstream\u001b[49m\u001b[43m(\u001b[49m\u001b[43m{\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m:\u001b[49m\u001b[43m \u001b[49m\u001b[43minput_messages\u001b[49m\u001b[43m}\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mconfig\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mstream_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mvalues\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m)\u001b[49m\u001b[43m:\u001b[49m\n\u001b[1;32m     10\u001b[0m \u001b[43m    \u001b[49m\u001b[43mchunk\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[38;5;124;43mmessages\u001b[39;49m\u001b[38;5;124;43m\"\u001b[39;49m\u001b[43m]\u001b[49m\u001b[43m[\u001b[49m\u001b[38;5;241;43m-\u001b[39;49m\u001b[38;5;241;43m1\u001b[39;49m\u001b[43m]\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mpretty_print\u001b[49m\u001b[43m(\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/Desktop/Code/langchain-academy/lc-academy-env/lib/python3.11/site-packages/langgraph/pregel/__init__.py:1335\u001b[0m, in \u001b[0;36mPregel.stream\u001b[0;34m(self, input, config, stream_mode, output_keys, interrupt_before, interrupt_after, debug, subgraphs)\u001b[0m\n\u001b[1;32m   1326\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m loop\u001b[38;5;241m.\u001b[39mstatus \u001b[38;5;241m==\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mout_of_steps\u001b[39m\u001b[38;5;124m\"\u001b[39m:\n\u001b[1;32m   1327\u001b[0m     msg \u001b[38;5;241m=\u001b[39m create_error_message(\n\u001b[1;32m   1328\u001b[0m         message\u001b[38;5;241m=\u001b[39m(\n\u001b[1;32m   1329\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mRecursion limit of \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mconfig[\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mrecursion_limit\u001b[39m\u001b[38;5;124m'\u001b[39m]\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m reached \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m   1333\u001b[0m         error_code\u001b[38;5;241m=\u001b[39mErrorCode\u001b[38;5;241m.\u001b[39mGRAPH_RECURSION_LIMIT,\n\u001b[1;32m   1334\u001b[0m     )\n\u001b[0;32m-> 1335\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m GraphRecursionError(msg)\n\u001b[1;32m   1336\u001b[0m \u001b[38;5;66;03m# set final channel values as run output\u001b[39;00m\n\u001b[1;32m   1337\u001b[0m run_manager\u001b[38;5;241m.\u001b[39mon_chain_end(loop\u001b[38;5;241m.\u001b[39moutput)\n",
      "\u001b[0;31mGraphRecursionError\u001b[0m: Recursion limit of 25 reached without hitting a stop condition. You can increase the limit by setting the `recursion_limit` config key.\nFor troubleshooting, visit: https://python.langchain.com/docs/troubleshooting/errors/GRAPH_RECURSION_LIMIT"
     ]
    }
   ],
   "source": [
    "# We supply a thread ID for short-term (within-thread) memory\n",
    "# We supply a user ID for long-term (across-thread) memory \n",
    "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"1\"}}\n",
    "\n",
    "# User input \n",
    "input_messages = [HumanMessage(content=\"Hi, my name is Lance\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I like to bike around San Francisco\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That sounds like a lot of fun! San Francisco has some beautiful routes for biking. Do you have a favorite trail or area you like to explore?\n"
     ]
    }
   ],
   "source": [
    "# User input \n",
    "input_messages = [HumanMessage(content=\"I like to bike around San Francisco\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Today I went biking in Marin Headlands\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "The Marin Headlands are stunning! The views of the Golden Gate Bridge and the ocean are incredible. Did you have a favorite spot or moment from your ride today?\n"
     ]
    }
   ],
   "source": [
    "# User input \n",
    "input_messages = [HumanMessage(content=\"Today I went biking in Marin Headlands\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc-academy-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
