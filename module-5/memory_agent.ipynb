{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Memory Agent\n",
    "\n",
    "## Review\n",
    "\n",
    "We created a chatbot that saves semantic memories to a single [user profile](https://langchain-ai.github.io/langgraph/concepts/memory/#profile) or [collection](https://langchain-ai.github.io/langgraph/concepts/memory/#collection).\n",
    "\n",
    "We introduced [Trustcall](https://github.com/hinthornw/trustcall) as a way to update either schema.\n",
    "\n",
    "## Goals\n",
    "\n",
    "Now, we're going to turn our chatbot into a simple [agent](https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/).\n",
    "\n",
    "The chatbot previously *always* reflected on the conversation and saved memories. \n",
    "\n",
    "The central difference is that the agent will decide *when* to save memories. \n",
    "\n",
    "For this, we're going to introduce a [router](https://langchain-ai.github.io/langgraph/concepts/agentic_concepts/) that allows the agent to save memories. \n",
    "\n",
    "We're going to make this a fully featured companion chatbot. To do that, we're going to have multiple different memory types. We're going to have one that is a \"user profile\", and another that remembers information about other important people in the user's life."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U langchain_openai langgraph trustcall langchain_core"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import os, getpass\n",
    "\n",
    "def _set_env(var: str):\n",
    "    # Check if the variable is set in the OS environment\n",
    "    env_value = os.environ.get(var)\n",
    "    if not env_value:\n",
    "        # If not set, prompt the user for input\n",
    "        env_value = getpass.getpass(f\"{var}: \")\n",
    "    \n",
    "    # Set the environment variable for the current process\n",
    "    os.environ[var] = env_value\n",
    "\n",
    "_set_env(\"LANGCHAIN_API_KEY\")\n",
    "os.environ[\"LANGCHAIN_TRACING_V2\"] = \"true\"\n",
    "os.environ[\"LANGCHAIN_PROJECT\"] = \"langchain-academy\""
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Adding a router\n",
    "\n",
    "There are many different [agent](https://langchain-ai.github.io/langgraph/concepts/high_level/) architectures to choose from.\n",
    "\n",
    "Here, we'll implement something simple: a router that decides when to update a user's profile, or the profile of key person in their life.\n",
    "\n",
    "This will reflect on the chat history and any prior memories to decide whether to update a profile.\n",
    "\n",
    "The updating itself will be handled by `Trustcall`, as before!\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from pydantic import BaseModel, Field\n",
    "from typing import Literal\n",
    "\n",
    "# Schema for binary decision to save memories\n",
    "class SaveMemory(BaseModel):\n",
    "    \"\"\"Whether to save information about the user, or about people in the user's life.\n",
    "\n",
    "    `user`: Call this if the conversation contains information that is worth updating the user's profile\n",
    "    `others`: Call this if the conversation contains information about OTHERS (not the user)\n",
    "    `both`: Call this if the converstion contains information about both the user AND others\n",
    "    `none`: Call this if no new information\n",
    "    \n",
    "    \"\"\"\n",
    "    store_memories: Literal['user', 'others', 'both', 'none'] = Field(description=\"Decision to save memories based on the conversation with the user.\", )"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "LangChain's chat model [chat model](https://python.langchain.com/docs/concepts/chat_models/) interface's [`with_structured_output`](https://python.langchain.com/docs/concepts/structured_outputs/#recommended-usage) method can be used to produce a binary decision.\n",
    "\n",
    "We'll bind the `SaveMemory` schema to the model, which will enforce that the model makes a binary decision about whether to save memories."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "_set_env(\"OPENAI_API_KEY\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'user'"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "from langchain_core.messages import HumanMessage, SystemMessage\n",
    "from langchain_openai import ChatOpenAI\n",
    "\n",
    "# Initialize the model\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "# Bind the schema to the model\n",
    "model_with_structure = model.with_structured_output(SaveMemory)\n",
    "\n",
    "# Current memory collection\n",
    "info = \"This user's name is Lance and he likes to bike.\"\n",
    "\n",
    "# System message\n",
    "system_msg = f\"\"\"You manage are deciding whether to update the memory collection for the user.\n",
    "Here is the current memory collection (it may be empty): <memories>{info}</memories>\n",
    "Here is the chat history. Assess whether the chat history contains any information that should be added to the memory collection.\"\"\"\n",
    "\n",
    "# Invoke with new information\n",
    "store_memories_flag = model_with_structure.invoke([SystemMessage(content=system_msg)]+[HumanMessage(content=\"I like to eat croissants\")])\n",
    "store_memories_flag.store_memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'both'"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invoke with new information\n",
    "store_memories_flag = model_with_structure.invoke([SystemMessage(content=system_msg)]+[HumanMessage(content=\"I like to eat croissants with my friend Ben who lives in SF\")])\n",
    "store_memories_flag.store_memories"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'none'"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Invoke with new information\n",
    "store_memories_flag = model_with_structure.invoke([SystemMessage(content=system_msg)]+[HumanMessage(content=\"Hi!\")])\n",
    "store_memories_flag.store_memories"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Graph definition \n",
    "\n",
    "We add a simple router, `route_message`, that makes a binary decision to save memories.\n",
    "\n",
    "The memory collection updating is handled by `Trustcall` in the `write_memory` node, as before!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/jpeg": "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",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "import uuid\n",
    "from IPython.display import Image, display\n",
    "\n",
    "from trustcall import create_extractor\n",
    "from typing import TypedDict\n",
    "\n",
    "from langchain_core.runnables import RunnableConfig\n",
    "from langchain_core.messages import merge_message_runs\n",
    "\n",
    "from langgraph.checkpoint.memory import MemorySaver\n",
    "from langgraph.graph import StateGraph, MessagesState, END, START\n",
    "from langgraph.store.base import BaseStore\n",
    "from langgraph.store.memory import InMemoryStore\n",
    "\n",
    "# Initialize the model\n",
    "model = ChatOpenAI(model=\"gpt-4o\", temperature=0)\n",
    "\n",
    "\n",
    "# Profile schema\n",
    "class Profile(BaseModel):\n",
    "    \"\"\"This is the profile of the user you are chatting with\"\"\"\n",
    "    name: str = Field(description=\"The user's name\")\n",
    "    job: str = Field(description=\"The user's job\")\n",
    "    age: str = Field(description=\"The user's age\")\n",
    "    interests: list[str] = Field(description=\"Interests that the user has\")\n",
    "\n",
    "\n",
    "class Person(Profile):\n",
    "    \"\"\"This is the profile of a person who is important to the user you are chatting with. This is NOT a profile for the user you are talking with\"\"\"\n",
    "    relation: str = Field(description=\"relation to the user (friend, sibling, spouse, etc). The more specific the better!\")    \n",
    "\n",
    "# Create the Trustcall extractors\n",
    "profile_extractor = create_extractor(\n",
    "    model,\n",
    "    tools=[Profile],\n",
    "    tool_choice=\"Profile\",\n",
    ")\n",
    "person_extractor = create_extractor(\n",
    "    model,\n",
    "    tools=[Person],\n",
    "    tool_choice=\"Person\",\n",
    ")\n",
    "\n",
    "# Chatbot instruction\n",
    "MODEL_SYSTEM_MESSAGE = \"\"\"You are a helpful chatbot. You are designed to be a companion to a user. \n",
    "\n",
    "You have a long term memory which keeps track of information you learn about the user over time, as well as key people in their life.\n",
    "\n",
    "User Profile:\n",
    "<user_profile>\n",
    "{user_profile}\n",
    "</user_profile>\n",
    "\n",
    "Key People:\n",
    "<key_people>\n",
    "{key_people}\n",
    "</key_people>\n",
    "\n",
    "If you want to update your memory of the user, please do so before responding by calling the `UpdateUser` tool.\n",
    "\n",
    "If you want to update your memory of other key people, please do so before responding by calling the `UpdatePeople` tool.\"\"\"\n",
    "\n",
    "class UpdateUser(TypedDict):\n",
    "    update_user: bool\n",
    "\n",
    "\n",
    "class UpdatePeople(TypedDict):\n",
    "    update_people: bool\n",
    "\n",
    "# Trustcall instruction\n",
    "TRUSTCALL_INSTRUCTION = \"\"\"Reflect on following interaction. \n",
    "\n",
    "Use the provided tools to retain any necessary memories about the user. \n",
    "\n",
    "Use parallel tool calling to handle updates and insertions simultaneously:\"\"\"\n",
    "\n",
    "# Node definitions\n",
    "def call_model(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "\n",
    "    \"\"\"Load memories from the store and use them to personalize the chatbot's response.\"\"\"\n",
    "    \n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Retrieve profile memory from the store\n",
    "    namespace = (\"profile\", user_id)\n",
    "    memories = store.search(namespace)\n",
    "    if memories:\n",
    "        user_profile = memories[0].value\n",
    "    else:\n",
    "        user_profile = None\n",
    "\n",
    "    # Retrieve people memory from the store\n",
    "    namespace = (\"people\", user_id)\n",
    "    memories = store.search(namespace)\n",
    "    key_people = \"\\n\".join(f\"{mem.value}\" for mem in memories)\n",
    "    \n",
    "    system_msg = MODEL_SYSTEM_MESSAGE.format(user_profile=user_profile, key_people=key_people)\n",
    "\n",
    "    # Respond using memory as well as the chat history\n",
    "    response = model.bind_tools([UpdatePeople, UpdateUser], parallel_tool_calls=False).invoke([SystemMessage(content=system_msg)]+state[\"messages\"])\n",
    "\n",
    "    return {\"messages\": [response]}\n",
    "\n",
    "\n",
    "def update_profile(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "\n",
    "    \"\"\"Reflect on the chat history and update the memory collection.\"\"\"\n",
    "    \n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Define the namespace for the memories\n",
    "    namespace = (\"profile\", user_id)\n",
    "\n",
    "    # Retrieve the most recent memories for context\n",
    "    existing_items = store.search(namespace)\n",
    "\n",
    "    # Format the existing memories for the Trustcall extractor\n",
    "    tool_name = \"Profile\"\n",
    "    existing_memories = ([(existing_item.key, tool_name, existing_item.value)\n",
    "                          for existing_item in existing_items]\n",
    "                          if existing_items\n",
    "                          else None\n",
    "                        )\n",
    "\n",
    "    # Merge the chat history and the instruction\n",
    "    updated_messages=list(merge_message_runs(messages=[SystemMessage(content=TRUSTCALL_INSTRUCTION)] + state[\"messages\"][:-1]))\n",
    "\n",
    "    # Invoke the extractor\n",
    "    result = profile_extractor.invoke({\"messages\": updated_messages, \n",
    "                                         \"existing\": existing_memories})\n",
    "\n",
    "    # Save save the memories from Trustcall to the store\n",
    "    for r, rmeta in zip(result[\"responses\"], result[\"response_metadata\"]):\n",
    "        store.put(namespace,\n",
    "                  rmeta.get(\"json_doc_id\", str(uuid.uuid4())),\n",
    "                  r.model_dump(mode=\"json\"),\n",
    "            )\n",
    "    tool_calls = state['messages'][-1].tool_calls\n",
    "    return {\"messages\": [{\"role\": \"tool\", \"content\": \"updated profile\", \"tool_call_id\":tool_calls[0]['id']}]}\n",
    "\n",
    "def update_people(state: MessagesState, config: RunnableConfig, store: BaseStore):\n",
    "\n",
    "    \"\"\"Reflect on the chat history and update the memory collection.\"\"\"\n",
    "    \n",
    "    # Get the user ID from the config\n",
    "    user_id = config[\"configurable\"][\"user_id\"]\n",
    "\n",
    "    # Define the namespace for the memories\n",
    "    namespace = (\"people\", user_id)\n",
    "\n",
    "    # Retrieve the most recent memories for context\n",
    "    existing_items = store.search(namespace)\n",
    "\n",
    "    # Format the existing memories for the Trustcall extractor\n",
    "    tool_name = \"People\"\n",
    "    existing_memories = ([(existing_item.key, tool_name, existing_item.value)\n",
    "                          for existing_item in existing_items]\n",
    "                          if existing_items\n",
    "                          else None\n",
    "                        )\n",
    "\n",
    "    # Merge the chat history and the instruction\n",
    "    updated_messages=list(merge_message_runs(messages=[SystemMessage(content=TRUSTCALL_INSTRUCTION)] + state[\"messages\"][:-1]))\n",
    "\n",
    "    # Invoke the extractor\n",
    "    result = person_extractor.invoke({\"messages\": updated_messages, \n",
    "                                         \"existing\": existing_memories})\n",
    "\n",
    "    # Save save the memories from Trustcall to the store\n",
    "    for r, rmeta in zip(result[\"responses\"], result[\"response_metadata\"]):\n",
    "        store.put(namespace,\n",
    "                  rmeta.get(\"json_doc_id\", str(uuid.uuid4())),\n",
    "                  r.model_dump(mode=\"json\"),\n",
    "            )\n",
    "    tool_calls = state['messages'][-1].tool_calls\n",
    "    return {\"messages\": [{\"role\": \"tool\", \"content\": \"updated people\", \"tool_call_id\":tool_calls[0]['id']}]}\n",
    "\n",
    "# Conditional edge\n",
    "def route_message(state: MessagesState, config: RunnableConfig, store: BaseStore) -> Literal[END, \"update_people\", \"update_profile\"]:\n",
    "\n",
    "    \"\"\"Reflect on the memories and chat history to decide whether to update the memory collection.\"\"\"\n",
    "    message = state['messages'][-1]\n",
    "    if len(message.tool_calls) ==0:\n",
    "        return END\n",
    "    else:\n",
    "        tool_call = message.tool_calls[0]\n",
    "        if tool_call['name'] == \"UpdatePeople\":\n",
    "            return \"update_people\"\n",
    "        else:\n",
    "            return \"update_profile\"\n",
    "\n",
    "# Create the graph + all nodes\n",
    "builder = StateGraph(MessagesState)\n",
    "\n",
    "# Define the flow of the memory extraction process\n",
    "builder.add_node(call_model)\n",
    "builder.add_node(update_people)\n",
    "builder.add_node(update_profile)\n",
    "builder.add_conditional_edges(\"call_model\", route_message)\n",
    "builder.add_edge(START, \"call_model\")\n",
    "builder.add_edge(\"update_people\", \"call_model\")\n",
    "builder.add_edge(\"update_profile\", \"call_model\")\n",
    "\n",
    "# Store for long-term (across-thread) memory\n",
    "across_thread_memory = InMemoryStore()\n",
    "\n",
    "# Checkpointer for short-term (within-thread) memory\n",
    "within_thread_memory = MemorySaver()\n",
    "\n",
    "# We compile the graph with the checkpointer and store\n",
    "graph = builder.compile(checkpointer=within_thread_memory, store=across_thread_memory)\n",
    "\n",
    "# View\n",
    "display(Image(graph.get_graph(xray=1).draw_mermaid_png()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Hi, my name is Lance.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateUser (call_FEZIwrGF58J2ckH3d2KGRyKG)\n",
      " Call ID: call_FEZIwrGF58J2ckH3d2KGRyKG\n",
      "  Args:\n",
      "    update_user: True\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "updated profile\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Hi Lance! It's great to meet you. How can I assist you today?\n"
     ]
    }
   ],
   "source": [
    "# We supply a thread ID for short-term (within-thread) memory\n",
    "# We supply a user ID for long-term (across-thread) memory \n",
    "config = {\"configurable\": {\"thread_id\": \"1\", \"user_id\": \"1\"}}\n",
    "\n",
    "# User input \n",
    "input_messages = [HumanMessage(content=\"Hi, my name is Lance.\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "I like to bike around San Francisco\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateUser (call_p4PPZEtHK9BzVlERntMjLUan)\n",
      " Call ID: call_p4PPZEtHK9BzVlERntMjLUan\n",
      "  Args:\n",
      "    update_user: True\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "updated profile\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "Biking around San Francisco sounds like a lot of fun! Do you have any favorite routes or spots you like to visit while biking?\n"
     ]
    }
   ],
   "source": [
    "# User input \n",
    "input_messages = [HumanMessage(content=\"I like to bike around San Francisco\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Yes, I went to the Marin headlands today. I went with Jenny my wife\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdatePeople (call_71kDR5z9x0SspXHY0f3SoU6A)\n",
      " Call ID: call_71kDR5z9x0SspXHY0f3SoU6A\n",
      "  Args:\n",
      "    update_people: True\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "updated people\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That sounds like a beautiful ride! The Marin Headlands offer some stunning views. How was the ride with Jenny? Did you both enjoy it?\n"
     ]
    }
   ],
   "source": [
    "# User input \n",
    "input_messages = [HumanMessage(content=\"Yes, I went to the Marin headlands today. I went with Jenny my wife\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can continue chatting. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Good - she is just starting to bike\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdatePeople (call_jDaRAcZrdy5YtvdO4ZYsi2NP)\n",
      " Call ID: call_jDaRAcZrdy5YtvdO4ZYsi2NP\n",
      "  Args:\n",
      "    update_people: True\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "updated people\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "That's great to hear! It's wonderful that Jenny is getting into biking. Do you have any tips or plans to help her as she starts out?\n"
     ]
    }
   ],
   "source": [
    "# Chat with the chatbot\n",
    "input_messages = [HumanMessage(content=\"Good - she is just starting to bike\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Lance', 'job': '', 'age': '', 'interests': ['biking around San Francisco']}\n"
     ]
    }
   ],
   "source": [
    "# Namespace for the memory to save\n",
    "user_id = \"1\"\n",
    "\n",
    "# Search \n",
    "for memory in across_thread_memory.search((\"profile\", user_id)):\n",
    "    print(memory.value)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "{'name': 'Jenny', 'job': 'beginner cyclist', 'age': '', 'interests': ['biking'], 'relation': 'wife'}\n"
     ]
    }
   ],
   "source": [
    "# Namespace for the memory to save\n",
    "user_id = \"1\"\n",
    "\n",
    "# Search \n",
    "for memory in across_thread_memory.search((\"people\", user_id)):\n",
    "    print(memory.value)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now we can create a new thread and chat with the chatbot again.\n",
    "\n",
    "It should retain the memories from the previous thread!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "What bakeries would you recommend for me and my wife?\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "San Francisco has some fantastic bakeries that you and Jenny might enjoy, especially if you're planning a biking trip around the city. Here are a few recommendations:\n",
      "\n",
      "1. **Tartine Bakery** - Known for its delicious bread and pastries, it's a must-visit for anyone in San Francisco.\n",
      "\n",
      "2. **B. Patisserie** - Offers a delightful selection of French pastries, including their famous kouign-amann.\n",
      "\n",
      "3. **Arizmendi Bakery** - A worker-owned cooperative bakery known for its fresh bread, pastries, and pizza.\n",
      "\n",
      "4. **Craftsman and Wolves** - Offers innovative pastries and a unique twist on classic bakery items.\n",
      "\n",
      "5. **Mr. Holmes Bakehouse** - Famous for their cruffins and other creative pastries.\n",
      "\n",
      "These spots are perfect for a sweet treat or a quick snack during your biking adventures. Enjoy!\n"
     ]
    }
   ],
   "source": [
    "# We supply a thread ID for short-term (within-thread) memory\n",
    "# We supply a user ID for long-term (across-thread) memory \n",
    "config = {\"configurable\": {\"thread_id\": \"2\", \"user_id\": \"1\"}}\n",
    "\n",
    "# Chat with the chatbot\n",
    "input_messages = [HumanMessage(content=\"What bakeries would you recommend for me and my wife?\")]\n",
    "\n",
    "# Run the graph\n",
    "for chunk in graph.stream({\"messages\": input_messages}, config, stream_mode=\"values\"):\n",
    "    chunk[\"messages\"][-1].pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Trace: \n",
    "\n",
    "https://smith.langchain.com/public/f267e203-d78a-4884-898f-8d5c84d5597c/r\n",
    "\n",
    "## TODO: Show in Studio\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.1"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
