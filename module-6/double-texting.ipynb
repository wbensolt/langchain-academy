{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Double Texting\n",
    "\n",
    "Seamless handling of [double texting](https://langchain-ai.github.io/langgraph/concepts/double_texting/) is important for handling real-world usage scenarios, especially in chat applications.\n",
    "\n",
    "Users can send multiple messages in a row before the prior run(s) complete, and we want to ensure that we handle this gracefully.\n",
    "\n",
    "## Reject\n",
    "\n",
    "A simple approach is to [reject](https://langchain-ai.github.io/langgraph/cloud/how-tos/reject_concurrent/) any new runs until the current run completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture --no-stderr\n",
    "%pip install -U langgraph_sdk"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from langgraph_sdk import get_client\n",
    "url_for_cli_deployment = \"http://localhost:8123\"\n",
    "client = get_client(url=url_for_cli_deployment)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Failed to start concurrent run Client error '409 Conflict' for url 'http://localhost:8123/threads/3e2f44a2-ba15-4017-bfc0-05df8212dbad/runs'\n",
      "For more information check: https://developer.mozilla.org/en-US/docs/Web/HTTP/Status/409\n"
     ]
    }
   ],
   "source": [
    "import httpx\n",
    "from langchain_core.messages import HumanMessage\n",
    "\n",
    "# Create a thread\n",
    "thread = await client.threads.create()\n",
    "\n",
    "# Create to dos\n",
    "user_input_1 = \"Add a ToDo to follow-up with DI Repairs.\"\n",
    "user_input_2 = \"Add a ToDo to mount dresser to the wall.\"\n",
    "config = {\"configurable\": {\"user_id\": \"Lance\"}}\n",
    "graph_name = \"task_maistro\" \n",
    "\n",
    "run = await client.runs.create(\n",
    "    thread[\"thread_id\"],\n",
    "    graph_name,\n",
    "    input={\"messages\": [HumanMessage(content=user_input_1)]}, \n",
    "    config=config,\n",
    ")\n",
    "try:\n",
    "    await client.runs.create(\n",
    "        thread[\"thread_id\"],\n",
    "        graph_name,\n",
    "        input={\"messages\": [HumanMessage(content=user_input_2)]}, \n",
    "        config=config,\n",
    "        multitask_strategy=\"reject\",\n",
    "    )\n",
    "except httpx.HTTPStatusError as e:\n",
    "    print(\"Failed to start concurrent run\", e)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add a ToDo to follow-up with DI Repairs.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_jUi4eEKN9Hhr1TIc1AqaSghf)\n",
      " Call ID: call_jUi4eEKN9Hhr1TIc1AqaSghf\n",
      "  Args:\n",
      "    update_type: todo\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "New ToDo created:\n",
      "Content: {'task': 'Follow-up with DI Repairs', 'time_to_complete': 10, 'solutions': ['Call DI Repairs to check on the status of the repair', 'Email DI Repairs for a written update', 'Review any previous communications with DI Repairs'], 'status': 'not started'}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I've added a new task to follow-up with DI Repairs to your ToDo list. If you need any more help, just let me know!\n"
     ]
    }
   ],
   "source": [
    "from langchain_core.messages import convert_to_messages\n",
    "\n",
    "# Wait until the original run completes\n",
    "await client.runs.join(thread[\"thread_id\"], run[\"run_id\"])\n",
    "\n",
    "# Get the state of the thread\n",
    "state = await client.threads.get_state(thread[\"thread_id\"])\n",
    "for m in convert_to_messages(state[\"values\"][\"messages\"]):\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Enqueue\n",
    "\n",
    "We can use [enqueue](https://langchain-ai.github.io/langgraph/cloud/how-tos/enqueue_concurrent/https://langchain-ai.github.io/langgraph/cloud/how-tos/enqueue_concurrent/) any new runs until the current run completes."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Add a ToDo to follow-up with DI Repairs.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_jUi4eEKN9Hhr1TIc1AqaSghf)\n",
      " Call ID: call_jUi4eEKN9Hhr1TIc1AqaSghf\n",
      "  Args:\n",
      "    update_type: todo\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "New ToDo created:\n",
      "Content: {'task': 'Follow-up with DI Repairs', 'time_to_complete': 10, 'solutions': ['Call DI Repairs to check on the status of the repair', 'Email DI Repairs for a written update', 'Review any previous communications with DI Repairs'], 'status': 'not started'}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I've added a new task to follow-up with DI Repairs to your ToDo list. If you need any more help, just let me know!\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Send Erik his t-shirt gift this weekend.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_i10a2SBqCYUJVRCc190wGx6Z)\n",
      " Call ID: call_i10a2SBqCYUJVRCc190wGx6Z\n",
      "  Args:\n",
      "    update_type: todo\n",
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Get cash and pay nanny for 2 weeks. Do this by Friday.\n"
     ]
    }
   ],
   "source": [
    "# Create a new thread\n",
    "thread = await client.threads.create()\n",
    "\n",
    "# Create new ToDos\n",
    "user_input_1 = \"Send Erik his t-shirt gift this weekend.\"\n",
    "user_input_2 = \"Get cash and pay nanny for 2 weeks. Do this by Friday.\"\n",
    "config = {\"configurable\": {\"user_id\": \"Lance\"}}\n",
    "graph_name = \"task_maistro\" \n",
    "\n",
    "first_run = await client.runs.create(\n",
    "    thread[\"thread_id\"],\n",
    "    graph_name,\n",
    "    input={\"messages\": [HumanMessage(content=user_input_1)]}, \n",
    "    config=config,\n",
    ")\n",
    "\n",
    "second_run = await client.runs.create(\n",
    "    thread[\"thread_id\"],\n",
    "    graph_name,\n",
    "    input={\"messages\": [HumanMessage(content=user_input_2)]}, \n",
    "    config=config,\n",
    "    multitask_strategy=\"enqueue\",\n",
    ")\n",
    "\n",
    "# Wait until the second run completes\n",
    "await client.runs.join(thread[\"thread_id\"], second_run[\"run_id\"])\n",
    "\n",
    "# Get the state of the thread\n",
    "state = await client.threads.get_state(thread[\"thread_id\"])\n",
    "for m in convert_to_messages(state[\"values\"][\"messages\"]):\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Interrupt\n",
    "\n",
    "We can use [interrupt](https://langchain-ai.github.io/langgraph/cloud/how-tos/interrupt_concurrent/) to interrupt the current run, but save all the work that has been done so far up to that point.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Never mind, Thanksgiving is the 28th! Order Ham for Thanksgiving by next Friday.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_ti2tr2wXga3pA0WokTi5ZD3z)\n",
      " Call ID: call_ti2tr2wXga3pA0WokTi5ZD3z\n",
      "  Args:\n",
      "    update_type: todo\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "Document f27e786f-c3ff-450c-b2e7-ded273a44721 updated:\n",
      "Plan: Update the deadline for the task 'Call parents back about Thanksgiving plans' to reflect the correct date of Thanksgiving, which is November 28, 2024. This involves changing the 'deadline' field from '2024-11-23T23:59:59' to '2024-11-28T23:59:59'.\n",
      "Added content: 2024-11-28T23:59:59\n",
      "\n",
      "New ToDo created:\n",
      "Content: {'task': 'Order Ham for Thanksgiving', 'time_to_complete': 20, 'deadline': '2024-11-22T23:59:59', 'solutions': ['Choose a ham supplier', 'Decide on the type and size of ham', 'Place the order online or by phone', 'Schedule delivery or pickup'], 'status': 'not started'}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I've updated your ToDo list to reflect the correct deadline for ordering the ham for Thanksgiving by next Friday, November 22nd. If there's anything else you need to adjust, just let me know!\n",
      "interrupted\n"
     ]
    }
   ],
   "source": [
    "# Create a new thread\n",
    "thread = await client.threads.create()\n",
    "\n",
    "# Create new ToDos\n",
    "user_input_1 = \"Order turkey for Thanksgiving by Friday.\"\n",
    "user_input_2 = \"Never mind, Thanksgiving is the 28th! Order Ham for Thanksgiving by next Friday.\"\n",
    "config = {\"configurable\": {\"user_id\": \"Lance\"}}\n",
    "graph_name = \"task_maistro\" \n",
    "\n",
    "interrupted_run = await client.runs.create(\n",
    "    thread[\"thread_id\"],\n",
    "    graph_name,\n",
    "    input={\"messages\": [HumanMessage(content=user_input_1)]}, \n",
    "    config=config,\n",
    ")\n",
    "\n",
    "second_run = await client.runs.create(\n",
    "    thread[\"thread_id\"],\n",
    "    graph_name,\n",
    "    input={\"messages\": [HumanMessage(content=user_input_2)]}, \n",
    "    config=config,\n",
    "    multitask_strategy=\"interrupt\",\n",
    ")\n",
    "\n",
    "# Wait until the second run completes\n",
    "await client.runs.join(thread[\"thread_id\"], second_run[\"run_id\"])\n",
    "\n",
    "# Get the state of the thread\n",
    "state = await client.threads.get_state(thread[\"thread_id\"])\n",
    "for m in convert_to_messages(state[\"values\"][\"messages\"]):\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "interrupted\n"
     ]
    }
   ],
   "source": [
    "# Confirm that the first run was interrupted\n",
    "print((await client.runs.get(thread[\"thread_id\"], interrupted_run[\"run_id\"]))[\"status\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Rollback\n",
    "\n",
    "We can use [rollback](https://langchain-ai.github.io/langgraph/cloud/how-tos/rollback_concurrent/) to interrupt the prior run of the graph and starts a new one with the double-texted input.\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "================================\u001b[1m Human Message \u001b[0m=================================\n",
      "\n",
      "Actually, add a ToDo to drop by Yoga in person on Sunday.\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "Tool Calls:\n",
      "  UpdateMemory (call_4pJxJmwdJRWOqOzfLOjnt1vD)\n",
      " Call ID: call_4pJxJmwdJRWOqOzfLOjnt1vD\n",
      "  Args:\n",
      "    update_type: todo\n",
      "=================================\u001b[1m Tool Message \u001b[0m=================================\n",
      "\n",
      "New ToDo created:\n",
      "Content: {'task': 'Drop by Yoga in person on Sunday', 'time_to_complete': 30, 'deadline': '2024-11-17T23:59:59', 'solutions': [\"Check the yoga studio's schedule for Sunday\", 'Prepare any necessary equipment or attire', 'Plan transportation to the studio', 'Consider inviting a friend to join'], 'status': 'not started'}\n",
      "==================================\u001b[1m Ai Message \u001b[0m==================================\n",
      "\n",
      "I've added the task to drop by Yoga in person on Sunday to your ToDo list. If there's anything else you need, feel free to let me know!\n"
     ]
    }
   ],
   "source": [
    "# Create a new thread\n",
    "thread = await client.threads.create()\n",
    "\n",
    "# Create new ToDos\n",
    "user_input_1 = \"Add a ToDo to call to make appointment at Yoga.\"\n",
    "user_input_2 = \"Actually, add a ToDo to drop by Yoga in person on Sunday.\"\n",
    "config = {\"configurable\": {\"user_id\": \"Lance\"}}\n",
    "graph_name = \"task_maistro\" \n",
    "\n",
    "rolled_back_run = await client.runs.create(\n",
    "    thread[\"thread_id\"],\n",
    "    graph_name,\n",
    "    input={\"messages\": [HumanMessage(content=user_input_1)]}, \n",
    "    config=config,\n",
    ")\n",
    "\n",
    "second_run = await client.runs.create(\n",
    "    thread[\"thread_id\"],\n",
    "    graph_name,\n",
    "    input={\"messages\": [HumanMessage(content=user_input_2)]}, \n",
    "    config=config,\n",
    "    multitask_strategy=\"rollback\",\n",
    ")\n",
    "\n",
    "# Wait until the second run completes\n",
    "await client.runs.join(thread[\"thread_id\"], second_run[\"run_id\"])\n",
    "\n",
    "# Get the state of the thread\n",
    "state = await client.threads.get_state(thread[\"thread_id\"])\n",
    "for m in convert_to_messages(state[\"values\"][\"messages\"]):\n",
    "    m.pretty_print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Confirm that the original run was deleted\n",
    "try:\n",
    "    await client.runs.get(thread[\"thread_id\"], rolled_back_run[\"run_id\"])\n",
    "except httpx.HTTPStatusError as _:\n",
    "    print(\"Original run was correctly deleted\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "{'run_id': '1efa2141-324b-6924-a03f-39aeb186e29b',\n",
       " 'thread_id': '6d105043-6cbd-4d88-a26a-b648b65efd29',\n",
       " 'assistant_id': 'ea4ebafa-a81d-5063-a5fa-67c755d98a21',\n",
       " 'created_at': '2024-11-13T23:07:37.599504+00:00',\n",
       " 'updated_at': '2024-11-13T23:07:37.599504+00:00',\n",
       " 'metadata': {},\n",
       " 'status': 'interrupted',\n",
       " 'kwargs': {'input': {'messages': [{'id': None,\n",
       "     'name': None,\n",
       "     'type': 'human',\n",
       "     'content': 'Add a ToDo to call to make appointment at Yoga.',\n",
       "     'example': False,\n",
       "     'additional_kwargs': {},\n",
       "     'response_metadata': {}}]},\n",
       "  'config': {'metadata': {'created_by': 'system'},\n",
       "   'configurable': {'run_id': '1efa2141-324b-6924-a03f-39aeb186e29b',\n",
       "    'user_id': 'Lance',\n",
       "    'graph_id': 'task_maistro',\n",
       "    'thread_id': '6d105043-6cbd-4d88-a26a-b648b65efd29',\n",
       "    'assistant_id': 'ea4ebafa-a81d-5063-a5fa-67c755d98a21'}},\n",
       "  'webhook': None,\n",
       "  'subgraphs': False,\n",
       "  'temporary': False,\n",
       "  'stream_mode': ['values'],\n",
       "  'feedback_keys': None,\n",
       "  'interrupt_after': None,\n",
       "  'interrupt_before': None},\n",
       " 'multitask_strategy': 'reject'}"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "state = await client.runs.get(thread[\"thread_id\"], rolled_back_run[\"run_id\"])\n",
    "state\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "lc-academy-env",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
